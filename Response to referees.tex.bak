\documentclass[a4paper, 12pt]{report}
\setlength\arraycolsep{2pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
\setcounter{tocdepth}{0}
\usepackage{graphicx}
\usepackage{chicago}
\usepackage{amsfonts}
\usepackage{pdfpages}
\bibliographystyle{chicago}


\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\fref}[1]{Figure \ref{#1}}
\newcommand{\sref}[1]{\S\ref{#1}}
\newcommand{\tref}[1]{Table \ref{#1}}
\newcommand{\aref}[1]{\ref{#1}}
\newcommand{\bi}{\begin{itemize}}
\renewcommand{\i}{\item}
\newcommand{\ei}{\end{itemize}}


\title{Integrated tools for coherent quantitative risk management}
\author{Weihao Choo \\ \\ Department of Applied Finance and Actuarial Studies \\ Macquarie University}
\date{}


\begin{document}


\maketitle

\section*{Abstract}




This thesis proposes and explores novel methods to measure risk and dependence across known probability distributions. Risk and dependence typically varies in finance and insurance, taking on benign values most of the time and occasional tail values triggered by crises and catastrophes. However common measures of dependence and risk indicate the overall result and mask variations across the probability distribution.


This thesis employs layers to represent various sections of random quantities and their probability distribution. Layers are standard constructs in excess--of--loss and stop--loss reinsurance, capital optimization and financial derivatives, and are known as tranches in collateralised debt obligations.


Developments in this thesis reveal insights to risk and diversification when random quantities are aggregated, and produce optimal strategies to reduce and manage risk. In addition proposed methods employ common concepts and hence form a consistent, an integrated analytical framework.


``Layer dependence" characterises dependence structures underlying random variables by measuring dependence between their layers. Layer dependence decomposes and spreads Spearman's rho across the joint distribution. In addition practical properties of Spearman's rho apply to layer dependence.

``Mean densities" and ``risk densities" indicate mean values and distortion risks of continuous layers forming random quantities. Mean and risk densities are akin to probability densities, where integrating yields means and risks of larger layers. Systematic and diversifiable risks are separated, and diversification varies inversely with layer dependence across the distribution.

Lastly the ``tradeoff premium" generalises distortion risk measures, such as conditional--tail--expectation, capturing upside risk in addition to downside risk. In financial and insurance markets with strong competition and limited capital, excessive focus on downside leads to opportunity costs.




\newpage


\section*{Acknowledgements}



\tableofcontents


\chapter{Thesis overview and literature}



\section{Introduction to this thesis}


Novel solutions are proposed in this thesis to address four critical problems in quantitative risk management. These problems relate to measuring dependence, analyzing sources of risk and diversification, and forming balanced measures of risk. Section \aref{qrm} provides an overview of quantitative risk management. Section \aref{questions} identifies the four problems addressed in this thesis. Subsequent sections of this chapter delves into each problem, explaining its role and importance in quantitative risk management, summarising and critiquing current solutions, and outlining proposed solutions.


Proposed solutions in this thesis draw on well established concepts in the literature, and addresses limitations of current approaches. The proposed solutions integrate to form a coherent analytical framework for quantitative risk management. Four papers describing the proposed solutions have been written and submitted to various journals for publication. These papers form the main body of this thesis.

Subsequent chapters are structured as follows:
\bi

\i Chapter 2 presents the paper ``Layer dependence as a measure of local dependence", an approach to measure dependence across percentiles of a joint probability distribution.

\i Chapter 3 presents the paper ``\textit{Mean and risk density curves}" which analyze sources of mean and risk for a single loss distribution.

\i Chapter 4 presents the paper ``\textit{Analyzing systemic risk and diversification}" which integrates layer dependence and mean and risk density curves to analyze systemic risk and diversification for multiple losses.

\i Chapter 5 presents the paper ``The tradeoff insurance premium as a two-sided generalisation of the distortion premium", which measures risk capturing upside in addition to downside.

\i Chapter 6 concludes this thesis by discussing how proposed approaches form an integrated quantitative risk management framework.

\ei



\section{Quantitative risk management}\label{qrm}


Risk relates to unpredictable, volatile outcomes having a positive or negative impact. Risk is inherent in financial and insurance markets. For example banks are exposed to movements in stock markets, interest rates, credit defaults and the state of the economy. Insurers are impacted by the volume of premium written as well as the number and size of insurance claims,  particularly from man-made and natural catastrophes.



Quantitative risk management quantifies and manages risk. \shortciteN{mcneil2005qrm} discusses the history, issues and common techniques of quantitative risk management. Quantitative risk management typically focuses on outcomes with negative impact. For instance banks and insurers calculate and hold capital buffers against unexpected losses. Capital buffers are driven by the magnitude of risk, as well as the aversion of the company, regulator, and other stakeholders. Another example of a focus on negative outcomes is the purchase of catastrophe reinsurance protection by insurance companies. Other risk management strategies include derivatives to hedge future uncertain outcomes, and early warning systems where risk indicators are monitored regularly with action taken when adverse movements are detected.


Quantitative risk management is increasingly important for financial and insurance companies. For example Solvency II \shortcite{eling2007solvency} requires insurers to hold capital commensurate with their levels of market, credit, underwriting, catastrophe and operational risks. Basel II \cite{engelmann2006basel} and more recently Basel III \cite{king2011basel} impose similar requirements on banks. Major insurers and banks typically develop stochastic models of their business operations and manage risks according to simulated results \shortcite{kaufmann2001introduction}. Quantitative risk management is also an important component of the broader Enterprise Risk Management (ERM) \cite{nocco2006enterprise}, where quantifiable and non-quantifiable risks are managed holistically.


Quantitative risk management is a broad area covering a wide range of topics. Of interest in this thesis are measures of dependence and risk. Specific interest areas are outlined in the next section. The importance of these interest areas in quantitative risk management, limitations of current approaches and proposed solutions are discussed in subsequent sections of this chapter. The following briefly describes dependence and risk measures:

\bi


\i Dependence measures capture the degree of association between random variables. Typical dependence measures are based on linear correlation. Dependence is a common feature of financial and insurance markets. For example returns from various stock markets are dependent, particularly when in distress \cite{rodriguez2007measuring}. Catastrophes create significant losses across insurance companies and lines of business such as property, motor and liability.

\i Risk measures quantify the magnitude and volatility of negative outcomes. The quantification provides critical input to optimal decision making. For example bank capital buffers are based on risks of stock market crashes, credit defaults and other risk factors \cite{king2011basel}. Reinsurance purchases by insurers are based on the level of catastrophe risk. Value-at-risk is a common risk measure but with shortcomings, and refined measures satisfying coherence properties have been proposed \shortcite{mcneil2005qrm}.

\ei
Dependence and risk measurement are related problems when random losses are aggregated. Strong dependence between random losses increases aggregate risk, as the simultaneous occurrence of extreme loss outcomes creates catastrophic consequences.



\section{Specific problems addressed in this thesis}\label{questions}


This thesis proposes novel solutions to the following four specific problems in dependence and risk measurement. Remaining sections of this chapter delve into each problem. The four problems are:

\bi

\i Measuring dependence between random losses. Of interest is local dependence at various parts of the joint distribution, rather than overall dependence. To illustrate the importance of local dependence, consider stock market returns which are highly dependent when in distress but less dependent under normal circumstances. Failure to capture this tail dependence leads to insufficient capital buffers against market risk.

\i Decomposing the mean and risk of a random loss and understanding contributions by various parts of the probability distribution. For example, for a highly skewed loss distribution such as the Pareto, most of the mean and risk are concentrated in the upper tail. Risk management strategies are then formulated to address key sources of mean and risk.

\i Analyzing systemic risk and diversification when random losses are aggregated. Aggregation reduces risk -- for example the market index is less volatile than individual stocks forming the index. Diversification represents the risk reduction and remaining risk is systemic. Of interest are key sources of systemic risk and diversification in the joint distribution so that, similar to the previous problem, optimal risk management strategies can be formulated.

\i Measuring risk reflecting upside in addition to downside. Despite the widespread focus on downside risk in the literature, upside risk is also important and neglecting upside risk leads to opportunity losses. For example, excessive focus on downside risk in insurance pricing leads to an uncompetitive premium. Acknowledging and reflecting favourable outcomes achieves a more balanced insurance premium.

\ei
For the first three problems described above, the literature extensively discusses measures of \textit{overall} dependence, risk and diversification, but offers minimal insights into how dependence, risk and diversification \textit{vary} across the probability distribution. For example linear correlation does not indicate differing dependence between random losses at, for example, their 50th, 75th and 99th percentiles. These insights are important because risk management strategies usually target and affect a certain part rather than the entirety of the probability distribution. For example, reinsurance protects against losses above the excess. Capital covers losses below itself. A detailed critique of the literature is performed in subsequent sections.




In this thesis, layers (\citeN{salzmann1963rating}, \citeN{evans2001exposure}) are used to represent parts of a loss. Layer is an insurance term indicating the loss amount above an excess and capped at a limit. Typical insurance and reinsurance contracts cover a loss layer. Capital surplus and shortfall are also loss layers. High loss layers represent tail outcomes.


VaRs


Developments in this thesis assert that solutions and insights to the above four problems are interrelated. For example, the systemic risk of a particular layer of a random loss (third problem) is positively related to local dependence between the same layer and other random losses (first problem). This explains the presence of high systemic risk and low diversification in financial and insurance markets when tail dependence is strong. Risk is measured consistently, using distortion \cite{wang1996pct}, across the last three problems.



The problems considered in this thesis are described generically and do not apply to specific financial or insurance contexts. Therefore proposed solutions in this thesis are relevant to financial or insurance problems involving risk and dependence.




Marginal behaviour of random variables is assumed known. The modeling of marginal behaviour is well established in the literature. Parametric or non-parametric distributions are typically first fitted to data, and tests are then performed to assess the suitability of the fit. References include \citeN{feller2008introduction} and \citeN{hogg2009loss}. Extreme value theory \cite{kotz2000extreme} addresses tail behaviour representing extreme outcomes.



A single period is assumed. Therefore time series of random variables, for example daily stock market returns over one year, are ignored. Time series models common in quantitative risk management, such as Autogressive Moving Average (ARMA) and Generalised Autoregressive Conditional Heteroskedasticity (GARCH) models, are discussed in \shortciteN{mcneil2005qrm} and \citeN{lamoureux1990heteroskedasticity}.




\section{Local dependence and its measurement}\label{local}


\subsection{Importance of local dependence}


Dependence is inherent in financial, insurance, commodities and other markets. For example interest rates, unemployment, stock market returns and credit defaults are dependent and reliant on the economy. In addition these quantities are dependent on corresponding quantities in other geographies and countries. Insurance claims from motor, property and liability classes are also dependent, due to their reliance on common economic and social factors, as well as weather patterns.


Measuring and subsequently modeling dependence is thus a critical part of quantitative risk management. To illustrate the importance of dependence, suppose a bank holds capital against the risk of stock market crashes and credit defaults by borrowers. If these two risk factors are strongly dependent, then large amounts of capital are required to cover market crashes and credit defaults occurring simultaneously. On the other hand if dependence is weak, then required capital is significantly lower since market crashes are unlikely to coincide with credit defaults -- a diversification benefit applies.



Dependence typically varies across joint distributions of financial and insurance quantities, giving rise to the need for \textit{local} dependence measures. For example moderate returns from stock market may be weakly dependent but extreme returns are strongly dependent (\citeN{rodriguez2007measuring} and \shortciteN{hartmann2004asset}). In insurance, attritional losses from various lines of business may be weakly dependent, however a single catastrophic event causes extreme losses across all lines. Failure to acknowledge varying dependence, and applying the average dependence across the entire joint distribution, leads to for example underestimation of tail risks where extreme outcomes from various risk factors occur simultaneously. The 2008 global financial crisis \cite{kolb2010lessons} is a relevant example.




\subsection{Current dependence measures}


Dependence lies between $\pm 1$, where $-1$ indicates countermonotonicity (perfect negative dependence) and $1$ indicates comonotonicity (perfect positive dependence). Positive dependence implies random variables tend to increase simultaneously, and vice versa for negative dependence. Dependence is measured either between random variables in their original values or percentile rank transforms. The latter is called ``rank dependence." The former is distorted by marginal distributions and covers a subset of $[-1,1]$, even with perfect dependence \shortcite{mcneil2005qrm}. Rank dependence is free of distortion by marginal distributions, and covers $[-1,1]$ completely.


Measures of overall dependence, including Pearson's correlation, Spearman's $\rho$ and Kendall's $\tau$  \shortcite{mcneil2005qrm}, do not characterise the dependence \textit{structure} of the joint distribution. As explained in the previous subsection, dependence typically varies across joint distributions of financial and insurance quantities, and tail dependence is common. Failure to measure and hence properly model the dependence structure result in ineffective quantitative risk management such as holding insufficient capital buffer.

Local dependence measures address this drawback of overall dependence measures, by measuring dependence at various points or parts of the joint distribution. The set of local dependence values calculated across the entire joint distribution characterises the dependence structure. Several local dependence measures have been proposed in the literature. The following describes these measures and their shortcomings:


\bi

\i Tail concentration \cite{venter2002tails} is the conditional probability of random variables falling in identical tail regions. The tail region is varied to yield dependence at various parts of the joint distribution. Calculating the conditional probability in the extreme tails yields coefficients of tail dependence by \citeN{joe1997multivariate}.

Tail concentration, being a probability, extracts partial information from the joint distribution. In particular actual values of random variables are excluded. As a result tail concentration does not always vary coherently across the joint distribution. The thesis refines tail concentration by incorporating dispersion between random variables.



\i Correlation curve \cite{bjerve1993correlation} applies regression principles and measures dependence between a random variable and a neighbourhood of another. The measurement combines conditional variances and changes in conditional expectations across neighbourhoods. A larger change in conditional expectation or lower conditional variance yields a higher correlation curve and vice versa.

Despite satisfying several coherence properties, correlation curve is difficult to calculate on data, due to the reliance on conditional expectation and conditional variance in a neighbourhood. Calculated values are volatile even for large samples.


\i \shortciteN{bairamov2003new}, \citeN{jones1996local} and \citeN{holland1987dependence} discuss bivariate local dependence measures. These capture dependence between different neighbourhoods of two random variables. In contrast tail concentration and correlation curves are univariate measures.

Bivariate local dependence measures maintain the dimension of the bivariate joint distribution, whereas univariate measures summarise and extract dependence information. This thesis focuses on univariate local dependence measures.



\ei
The above local dependence measures do not have a direct relationship with overall dependence measures such as Pearson correlation, Spearman's $\rho$ and Kendall's $\tau$. As a result local and overall dependence may have inconsistent values. For example local dependence may be consistently or mostly higher than overall dependence. Layer dependence, a local dependence measure proposed in this thesis, achieves consistency with Spearman's $\rho$. Layer dependence also satisfies several other practical properties. The next subsection discusses layer dependence.




\subsection{Layer dependence as a local dependence measure}



This thesis proposes a local dependence measure called ``layer dependence." Layer dependence captures rank dependence and is therefore calculated entirely from the copula \cite{nelson1999ic} of two random variables. As discussed in the previous subsection, rank dependence is free from distortion by marginal distributions. Chapter 2 defines, illustrates and analyzes layer dependence.


Layer dependence varies coherently across the joint distribution. For a joint distribution exhibiting weak lower tail dependence and strong upper tail dependence, layer dependence increases from near $0$ to near $1$. Layer dependence is higher when points simulated from the joint distribution are tightly clustered around the $45^{\circ}$ line, and lower if points are dispersed.


Layer dependence enhances and outperforms current local dependence measures described in the previous subsection. Layer dependence refines tail concentration by including average dispersion between percentile ranks of both random variables. Layer dependence calculations on data are also simpler and more stable than correlation curves. Layer dependence is a univariate local dependence function and is thus easier to interpret than bivariate measures. Layer dependence also possesses coherence properties discussed below.

The concept and definition of layer dependence are as follows. The percentile rank of a random variable is first decomposed into layers. Each layer represents movements in the random variable across a percentile. Layer dependence is then the covariance between a layer and the percentile rank of another random variable. A scaling factor is included to ensure layer dependence is one if random variables are comonotonic. Hence layer dependence captures rank dependence between local movements of a random variable and another random variable. Correlation curve achieves a similar measurement, and calculations show that layer dependence and correlation curve have similar values across the joint distribution or copula.


Layer dependence possesses practical properties similar to Spearman's $\rho$: between $-1$ and $1$, constant and equal to $-1$, $0$ and $1$ for countermonotonic, independent and comonotonic random variables, sign switching when ranking order reverses, and taking on higher values when dependence is stronger.


Layer dependence has a direct relationship with Spearman's $\rho$. Taking a weighted average of layer dependence values across all layers is Spearman's $\rho$. This relationship is intuitive -- averaging local dependence yields overall dependence. Weights attached to layer dependence values are quadratic, peaking at the median layer and approaching zero at the tails. These weights imply Spearman's $\rho$ understates tail dependence and hence overall dependence when tail dependence is present and important. More appropriate overall dependence measures are formed by averaging layer dependence values using weights reflecting the importance of dependence at various layers.

Layer dependence captures tail dependence consistently with coefficients of tail dependence by \citeN{joe1997multivariate}. Layer dependence at extreme layers and coefficients of tail dependence are both one when tail dependence is perfect. Perfect tail dependence requires random variables to simultaneously attain their maximum or minimum values.


Layer dependence is hence a useful tool to summarise and present the dependence structure underlying a copula or data. For a parametric copula, implications of its parametric form and parameters on the dependence structure are not always apparent. Similar problems apply when data is scarce or volatile and the dependence structure is not easily visualized.








Layer dependence offers an alternative method of copula modeling. First compute layer dependence values from data, and smooth the values parametrically or non-parametrically. Adjust, if necessary, to incorporate expert opinion on the dependence structure (for example tail dependence). A copula is then fitted to refined layer dependence values. The fitted copula overcomes the inflexibility of parametric copulas to closely capture the dependence structure exhibited in data, whilst avoiding uncertainties and instabilities of empirical copulas at the other extreme. \shortciteN{denuitactuarial}, \citeN{oakes1989bivariate} and \citeN{genest1993statistical} discusses the fitting of parametric copulas. \citeN{czado2010pair} proposes a semi-parametric approach based on vine copulas, where parametric bivariate copulas are connected sequentially to form multivariate copulas.






\section{Mean and risk decomposition}\label{decompose}


\subsection{Risk measurement and decomposition}

It is critical in quantitative risk management to assign risk values to random variables such as insurance losses, credit defaults and stock market returns. Risk values or risks provide inputs to risk management decisions. For example insurance risk drives premium loadings and capital buffers. Credit and market risks influence not only capital buffers, but also investment decisions and derivative hedging positions.


A risk measure assigns risks to random variables based on their probability distribution. Common risk measures such as standard deviation, value-at-risk and conditional-tail-expectation are discussed in \shortciteN{mcneil2005qrm} and \citeN{young2004premium}. Risk varies with the selected risk measure, and some risk measures are more appropriate than others in certain circumstances. Risk typically increases with volatility and skewness. Risk aversion also influences risk measurement -- greater risk aversion leads to greater risk and vice versa, whilst risk neutrality implies zero risk.


This thesis studies risk behaviour of a probability distribution. Similar to dependence, two random variables may have equal risk but their risks may vary differently across the probability distribution. For a skewed probability distribution capturing extreme outcomes such as catastrophic insurance losses or stock market crashes, risk is lower at moderate percentiles but higher at extreme percentiles. A coherent analysis of risk behaviour applies a single risk measure throughout. Risks of various parts of the probability distribution are computed and analyzed, and the sum of  these risks is consistent with overall risk. Layers are commonly used to decompose a random variable and its distribution -- see next subsection.

Analyzing risk behaviour is important for effective quantitative risk management. The analysis yields strategies targeting high risk areas of the loss. For example, excess-of-loss reinsurance covers losses above a threshold, and an optimal threshold reflects risk behaviour in the tails. A lower threshold leads to wider risk coverage but higher reinsurance cost, whereas residual risk is high with a high threshold. Setting an appropriate capital buffer also involves an analysis of risk behaviour below and above the capital level. In finance, pricing collaterised debt obligations and other derivatives require an understanding of mean and risk of each tranche.


Risk measures typically focus on downside (stock market losses, insurance losses) rather than upside (stock market gains, insurance profit). Neglecting upside leads to opportunity costs, for example uncompetitive insurance premiums and excessive capital buffers. Balanced risk measurement is separately studied in this thesis. A overview in provided in section \aref{balanced}.



\subsection{Current approaches to measure mean and risk across layers of a loss}


This thesis measures mean and risk across layers of a random loss. A non-negative random variable is formed by additive, comonotonic layers. The $[a,b]$ layer is the excess of the random variable over $a$, capped at $b-a$. Further the layer $[a,\infty]$ is the tail excess above $a$. Statistical properties of layers are discussed in \citeN{campana2014risk}, \citeN{wang1998actuarial}, \citeN{wang1995insurance} and \citeN{miccolis1977theory}. \citeN{lee1988mathematics} adopts a graphical approach to explain key concepts and results.

Layers are standard insurance and financial constructs. For example insurance and excess-of-reinsurance covers a loss layer from the excess or deductible to the limit. Capital buffers divide the loss into two layers -- capital surplus and shortfall. Financial quantities such as derivative payouts and collatorised debt obligations also involve layers, commonly called tranches. High layers capture rare, extreme outcomes and low layers characterise common, attritional outcomes.

The following summarises current literature on risk measurement across loss layers. The literature in this area is arguably less established compared to measures of overall risk. As explained in the previous subsection, of interest is risk behaviour across the probability distribution rather than overall risk, in order to gain risk insights and form targeted risk management strategies.
\bi

\i \citeN{wang1995insurance} calls the survival function the premium layer density as it computes the expected value or premium of infinitesimally small layers. The premium layer density is then distorted to yield risk-adjusted premiums. Integrating the distorted premium layer density forms the distorted risk measure, which covers examples such as the proportional hazards premium and conditional-tail-expectation \cite{choo2009loss}. \citeN{wang1995insurance} also applies the distorted premium layer density to investigate premiums under increasing limits of an insurance contract.

\i \citeN{ladoucette2006analysis} analyzes  risk measures  including value-at-risk, variance, and coefficient of variation across layers of an insurance loss. The analysis is also extended to consider layers of a random sum of insurance losses.

\i \citeN{hurlimann1998distribution} uses a distortion risk measure involving a two-stage loss transformation and the  Hardy-Littlewood pricing principle. This distortion risk measure is used to construct distribution-free layer premiums with several other practical properties.

\i Particular measures of overall risk focus on tail regions of a random loss. For example conditional-tail-expectation is the expected value of losses beyond a threshold, and adding the scaled variance of these losses yields the modified-tail-variance \cite{furman2008weighted}. Varying the threshold yields risks across various tail regions of the loss.


\i  \citeN{salzmann1963rating} and \citeN{evans2001exposure} perform empirical studies of appropriate premiums rates across loss layers for property insurance. \citeN{finger1976estimating} performs a similar study, assuming a lognormal loss distribution.

\ei
When an additive risk measure such as distortion is used, adding premiums or risks of layers yields the same for the combined layer. The thesis applies distortion to decompose and measure risk across layers. However, as discussed in the next subsection, layers are expressed differently from current approaches. This approach establishes links with two other interest areas in this thesis -- analysis of local dependence and diversification.




\subsection{Mean and risk densities}


This thesis constructs mean and risk densities indicating mean and risk values of infinitesimally small layers. These constructs yield solutions and insights to insurance and financial problems which are difficult or awkward to express and solve using standard statistical approaches. Risk densities are also integrated with other developments in this thesis on local dependence, systemic risk and diversification.


A similar approach as \citeN{wang1995insurance} is adopted. Risk is measured using distortion, the difference between mean under a distorted distribution and original mean. As distortion risks are additive over comonotonic random variables, and layers are comonotonic, integrating risk densities over an interval yields the risk of the integrated layer. The same result applies to mean densities. Hence mean and risk densities are analogous to probability densities, representing statistical quantities over an infinitesimally small area, with integration yielding the same over a larger area. Total areas under mean and risk densities represent overall mean and risk, respectively.



The novel feature of mean and risk densities in this thesis is they are defined over layers with endpoints expressed as values-at-risk (VaRs) or percentiles, rather than dollar values which is the case in the literature. Layers used in this thesis, called VaR layers, adjust to the shape and scale of the probability distribution since VaRs represent relative points in the distribution. For example the layer in excess of the $95\%$ VaR or 95th percentile captures the top $5\%$ of outcomes. On the other hand, the layer from 1 to 2 million dollars, for example, may be a remote or extreme layer for a probability distribution but typical for another.


Defining mean and risk densities over VaR layers in addition delivers the following properties, results and insights:
\bi

\i Mean and risk densities are constructed and graphed over the unit interval on the horizonal axis representing the VaR threshold or cumulative probability (for example the 95th VaR corresponds to $0.95$). Scale effects on mean and risk density values are isolated and captured in the vertical axis. Hence mean and risk densities across probability distributions are comparable and can be plotted on the same graph. In contrast current approaches, where layers are expressed in dollar terms, reflect scale effects on both horizontal and vertical axes.

\i Mean and risk densities are decomposed into products of a function not involving the probability distribution, and VaR spacing representing the derivative of VaR with respect to the threshold or the spacing between successive VaRs. A larger VaR spacing indicates a larger width of the VaR layer and hence higher mean and risk. Hence effects of the probability distribution are separated out and appear identically in both mean and risk densities.

\i Following the previous point, the risk ratio of a VaR layer, or the ratio between mean and risk densities, only varies with the VaR threshold and distortion operator forming distortion risk. Risk ratios are independent of the probability distribution. In addition risk ratios are increasing, hence higher VaR layers are relatively riskier.


\i The mean density is shown to be flat and equal to the mean value for an exponential distribution. Hence probability distributions with increasing mean densities (for example Pareto) are more skewed than the exponential, since VaR spacings increase at a relatively higher rate. Vice versa for probability distributions with decreasing mean densities (for example Weibull with certain parameters).

\i The overall risk ratio is an average of risk ratios weighted by the mean density. As risk ratios are increasing and independent of the probability distribution, a mean density with larger values at higher values yields a higher overall risk ratio. Hence skewed distributions are relatively riskier overall.


\i Mean and risk densities, when applied to practical problems, yields optimal quantities expressed as VaRs instead of dollars. These optimal quantities include capital buffer, reinsurance excess and limits, and contract terms for financial derivatives. As discussed above, VaRs represent relative points in the probability distribution and are hence more interpretable quantities than dollars. In addition VaRs are standard insurance and financial constructs. For example Solvency II insurance regulation applies $90\%$ and $99.5\%$ VaRs \shortcite{eling2007solvency} in capital requirements. Banking regulations Basel II and more recently Basel III also reference VaRs in risk measurement \shortcite{chernobai2008operational}.


\i Mean and risk densities on VaR layers integrate layer dependence discussed in the previous section with the analysis of systemic risk and diversification discussed in the next section. Hence integrated approaches and insights are achieved by adopting layers defined on VaRs rather than dollars.

\ei
Mean and risk densities provide solutions and insights to pricing, capital and risk management problems. These include for example optimal capital buffers and reinsurance arrangements. Focus is typically placed on layers with large mean or risk.





\section{Systematic risk and diversification}\label{diversification}


\subsection{Concepts of systematic risk and diversification}


Risk reduces when random variables are aggregated. This risk reduction is known as diversification. For example the investment return on an index is less volatile compared to individual components forming the index. Investment returns also stabilise when assessed over a longer period of time. Pooling insurance claims from a large number of policies reduces claims volatility to an acceptable level. Diversification arises when adverse outcomes for a random variable is offset by neutral or favourable outcomes in other random variables. Hence diversification weakens when random variables become more dependent, moving in tandem and more likely to simultaneously attain adverse outcomes.


Diversification implies the risk of a random variable is split into diversifiable and non-diversifiable. The latter is known as systematic risk in finance \cite{luenberger1998is}. Systematic risk contributes to aggregate risk, while diversifiable risk is eliminated upon aggregation. In insurance, systematic risks add up to aggregate risk and are hence an allocation of aggregate risk to component random variables \cite{kalkbrener2005aac}. Axioms for coherent risk allocation in \citeN{denault2001coherent} and \citeN{kalkbrener2005aac} propose no undercut.


Similar to risk and dependence discussed in the previous two sections of this chapter, systematic risk and diversification varies across the probability distribution. Developments in this thesis show that the extent of diversification across the distribution is inversely related to local dependence with the aggregate random variable such as the index return or aggregate insurance loss. Current literature, further discussed in the next subsection, makes this observation usually in an intuitive manner rather than under a formal approach.


Developing insights into systematic risk and diversification yields optimal risk management strategies targeting areas of the joint distribution with high systematic risk and low diversification, ultimately reducing aggregate risk. For example, excess-of-loss reinsurance is purchased to cover tails of losses with high rather than low systematic risk. Consider a company comparising of business units. The systematic or allocated risk of a business unit drives its risk-adjusted performance and remuneration. Hence it is critical every business unit to understand its systematic risk and behaviour across the probability distribution.



\subsection{Overview of current approaches}


Approaches to derive systematic or allocated risks are well established in the literature. An overview is shown below. Current approaches provide broad insights into drivers of systematic risk, usually the dependence between aggregated random variables. This thesis provides further insights by analyzing systematic risk and diversification across the probability distribution.

The following is an overview of current approaches to derive systematic or allocated risk:
\bi

\i In the capital asset pricing model (\citeN{luenberger1998is}, \citeN{sharpe1964cap}), the systematic risk of a security is proportional to correlation between its return and the market return, whilst overall risk of the security is the standard deviation of its return.

\i \citeN{choo2010determining} provides insights to allocated risks similar to the capital asset pricing model. By applying the Euler allocation principle (\shortciteN{mcneil2005qrm}, \citeN{buch2008coherent}) to distortion risk measurement described in the previous section, the  risk allocated to a random loss is its covariance with a function of the aggregate loss. \citeN{tsanakas2006risk} and \citeN{furman2008weighted1} show similar results.


\i The Euler allocation principle satisfies coherence axioms described in \citeN{denault2001coherent} and \citeN{kalkbrener2005aac}. These axioms include no undercut (allocated risk is less than standalone risk), symmetry (equal allocation to random variables with equal risk contribution) and riskless allocation (no allocation to risk-free random variables). Applying game theory \cite{shapley1974values} yields consistent results. Other properties and applications of Euler allocation are discussed in \citeN{tasche2007capital}.


\i \citeN{myers2001capital} and \citeN{sherris2006solvency} derive allocations based on option values. \shortciteN{dhaene2012optimal} proposes a general approach by minimising differences between allocated risk and losses. \shortciteN{van2012excess} argues against Euler allocation and performs an allocation by minimising expected shortfall in various portfolios. \citeN{cummins2000allocation} and \citeN{venter2004cas} summarise and critique current allocations.



\ei




\subsection{Analytical framework for systematic risk and diversification}


This thesis builds a framework to analyze systematic risk and diversification across probability distributions. The framework integrates layer dependence discussed in section \aref{local} and risk densities in section \aref{decompose}. Insights gained from the proposed framework are critical to advanced quantitative risk management involving multiple dependent random losses and their aggregate.


Cornerstone to the proposed framework are systematic risk densities indicating systematic risks of VaR layers forming a random loss. These risk densities are akin to those proposed in section \aref{decompose}. However risk densities in section \aref{decompose} apply to isolated rather than aggregated random variables, and hence include non-diversifiable risk. As described in section \aref{decompose}, layers are standard insurance and financial constructs. In addition VaR layers adjust to the shape and scale of the probability distribution, and are superior to layers expressed in dollars.

Measure systematic risk according to \citeN{choo2010determining} by applying Euler allocation to distortion risk. Thus the systematic risk of a layer is its covariance with a function of the aggregate loss. Since covariances are additive, integrating the systematic risk density over an interval yields the systematic risk of the integrated layer, and the entire area under the density is the overall systematic risk as per \citeN{choo2010determining}.


Taking the ratio between the systematic risk density and standalone risk density in section \aref{decompose} reveals the lack of diversification in each layer. The ratio reduces to a variant of layer dependence, discussed in section \aref{local}, between the layer and the aggregate loss. Hence local dependence explains and controls systematic risk and diversification across the probability distribution. Strong local dependence increases systematic risk and reduces diversification.


The link between local dependence and diversification across the distribution explains large systematic risks in financial markets exhibited for example during the 2008 global financial crisis \cite{kolb2010lessons}. This is despite relatively weak overall correlations observed over a long period of time. Strong tail dependence in financial markets (\citeN{rodriguez2007measuring} and \shortciteN{hartmann2004asset}), coupled with large tail risks (\citeN{hsieh1988statistical}, \citeN{cont2001empirical}) before diversification reflecting skewed return distributions, lead to significant amounts of non-diversifiable or systematic risk. Strong diversification below the tails does not significantly reduce overall risk as risks of individual return distributions are concentrated in the tails where diversification is weak.



Insights into systematic risk and diversification are critical to advanced risk management involving multiple, dependent random variables. By plotting and comparing standalone and systematic densities of a loss, layers with high and low diversification are identified and addressed accordingly. For example, reinsurance, hedging and other mitigation actions target individual tails with large systematic risk and weak diversification, even though standalone risks may be equal. This strategy reduces aggregate risk most effectively at minimal cost.


This thesis also allocates the mean and risk density of the aggregate loss to component losses. The allocation is critical when risk management strategies target aggregate loss layers, such as stop-loss reinsurance and aggregate hedging, and their costs are allocated to individual losses. The allocation applies  conditional mean sharing where a random aggregate loss is allocated to individual losses based on conditional expectations \cite{denuit2012convex}. The allocated risk density for a loss differs from its systematic risk density -- layers refer to different losses. The latter uses layers of the individual loss, whilst the former refers to aggregate loss layers. Both densities indicate risk contributions to aggregate risk. In addition allocated mean and risk densities integrate to the overall mean and systematic risk of the loss, hence the allocation is unbiased.





\section{Taking a balanced view of risk}\label{balanced}


\subsection{Two-sided versus one-sided risk measurement}


Risks measured from random insurance and financial quantities form critical inputs to for example risk margins, capital buffers, and limits on derivatives exposure. Risk measures are known as premium principles in insurance as they assign a premium to a random claims outcome. Risk measures and premium principles are well established in the literature, and common examples are discussed in \citeN{young2004premium} and \shortciteN{mcneil2005qrm}.


Due to the widely perceived negative consequences of volatility, risk measures (or premium principles) are typically one-sided and quantify adverse outcomes above the mean value or a higher threshold. Common one-sided risk measures are discussed in the next subsection. On the other hand two-sided risk measures capture favourable in addition to adverse outcomes. The distinction between one-sided and two-sided risk measures is well articulated in \shortciteN{dhaene2003economic}:

\begin{quote}
\textit{Two-sided risk measure (TRM): A two-sided risk
measure measures the ``distance" between the
risky situation and the corresponding risk-free
situation when both favorable and unfavorable
discrepancies are taken into account.}

\textit{One-sided risk measure (ORM): A one-sided
risk measure measures the “distance” between
the risky situation and the corresponding risk-free
situation when only unfavorable discrepancies
contribute to the ``risk."}
\end{quote}
Two-sided, balanced risk measurement is crucial in modern financial and insurance markets where competition is intense and unnecessary conservatism results in opportunity costs. The importance of capturing upside risk, and strategies of doing so, are discussed generally in \citeN{hillson2002extending} and \citeN{hillson2003effective}. For example when setting capital buffers, excessive conservatism leads to high buffers and high holding costs, whereas taking a more balanced view with lower buffers yields potentially higher shareholder returns. In insurance pricing, taking a one-sided negative view of claim costs results in a high risk loading and an uncompetitive premium, leading to a loss of business to competitors with less pessimistic and more realistic views.





\subsection{Current approaches}


The following are commonly used risk measures or premium principles. They are generally one-sided and focus on downside risk or adverse outcomes.
\bi

\i Value-at-risk or VaR \cite{dowd2006after} is a suitably high quantile of the probability distribution. VaR is commonly used in insurance and finance. For example Solvency II insurance regulation applies $90\%$ and $99.5\%$ VaRs \shortcite{eling2007solvency} in capital requirements. Banking regulations Basel II and more recently Basel III also reference VaRs in risk measurement \shortcite{chernobai2008operational}.


\i Conditional-tail-expectation or CTE \cite{rockafellar2002conditional} is the average of outcomes beyond a specified quantile or VaR. CTE addresses shortcomings of VaR, by reflecting the magnitude of outcomes above the VaR and satisfying subadditivity \cite{dowd2006after}. CTE is used in Swiss solvency regulations \cite{embrechts2014statistics}.


\i Distortion risk measures \cite{wang1996pct} are expectations under magnified survival probabilities, implying adverse outcomes are more likely. Distortion risk measures capture CTE, proportional hazard and other risk measures. \citeN{choo2009loss} shows the equivalence between distortion risk measures, loss aversion reserves and spectral risk measures \cite{acerbi2002spectral}. Loss aversion reserves and spectral risk measures are weighted averages of quantiles.


\i The zero utility premium principle \cite{gerber1985additive} sets the premium as the certainty equivalent of a random loss using a risk averse utility function. The premium always exceeds the expected loss. Using the exponential utility function yields the exponential premium, which is a weighted average of Esscher premiums \cite{van1989properties}. \citeN{heilpern2003rank} applies thr principle using rank-dependent utility theory \cite{quiggin1982theory}, whilst \citeN{kaluszka2011pricing} proposes a similar approach using cumulative prospect theory \cite{tversky1992apt}.


\ei
In the above examples there is a one-sided bias on negative outcomes, and there is always a positive loading above the mean. Although it can be argued that excessive conservatism is avoided with appropriate selection of risk parameters, there is no explicit allowance for upside risk or favourable outcomes. This thesis proposes an approach which explicitly captures and controls the relative importance of upside and downside risks. The approach is discussed in the next subsection.






\subsection{Tradeoff premium as a two-sided risk measure}


This thesis proposes ``tradeoff premiums" which are two-sided extensions of one-sided distortion risk measures. Upside and downside risks are explicitly captured and a ``loss appetite" controls their relative importance. Close links are established with subjective probability in cumulative prospect theory.



Tradeoff premiums are weighted premiums \cite{furman2008weighted}, with U-shaped instead of increasing weights. Similar to \citeN{choo2009loss}, weights are formulated in terms of loss percentile ranks. U-shaped weights stress the importance of favourable and unfavourable outcomes. An exogenous loss appetite defines the turning point of the weights, and hence controls the relative importance of upside and downside risks. A low loss appetite implies weights are mostly increasing and generates a conservative premium dominated by downside risk. On the other hand a high loss appetite creates mostly decreasing weights and an aggressive premium with greater focus on upside risk.



Cumulative prospect theory supports a U-shaped weight function forming tradeoff premiums. In cumulative prospect theory, extreme, unlikely outcomes are over-weighted while average, likely outcomes are under-weighted. Further S-shaped distortion operators are implied from tradeoff premiums, consistent with probability adjustment in cumulative prospect theory.



Manipulating tradeoff premiums yields weighted averages of a distortion risk and its ``dual" \cite{wang2000cdo}. Example tradeoff premiums include the two-sided VaR, a weighted average of lower and upper VaRs. The two-sided CTE is a weighted average of CTEs separately capturing lower and upper tails. The loss appetite controls the weights. This property emphasizes the two-sided nature of tradeoff premiums.



Tradeoff premiums fit the description of two-sided risk measures described in \shortciteN{dhaene2003economic} -- the distance between risky and risk-free positions where the risky position captures favourable and unfavourable outcomes. Subtracting the mean loss (risk-free position) from the tradeoff premium yields a loading and discount, capturing the volatility of outcomes above and below the loss appetite respectively. Therefore the difference between the tradeoff premium and the mean loss depends on the relative volatility of the two tails separated at the loss appetite. Higher upper tail volatility yields an overall positive difference and vice versa.



Tradeoff premiums satisfy translation invariance, positive homogeneity and monotonicity properties of coherent risk measures \shortcite{artzner1999cmr}. Only subadditivity is not satisfied in general -- the tradeoff premium of a sum of random losses may exceed the sum of individual tradeoff premiums. Tradeoff premiums are not subadditive due to their two-sided nature. Downside and upside risks have opposite impact on tradeoff premiums and both reduce upon aggregation. For right skewed loss distributions, downside risk dominates upside risk, yielding subadditive tradeoff premiums. Conversely left skewed loss distributions give rise to superadditivity.






\section{Conclusion}\label{conclusion}




Layer dependence, mean and risk densities, diversification analysis and tradeoff premiums address separate problems in risk and dependence analysis. Layer dependence analyzes dependence variation across the probability distribution. Mean and risk densities perform similar behavioural analysis. The diversification analysis assess the impact on risk densities when random quantities are aggregated. Tradeoff premiums extends one-sided risk measurement to capture upside risk in addition to downside risk.

Consistent methods and principles are applied across all proposed solutions in this thesis. Hence proposed solutions form an integrated approach to risk and dependence analysis. For example distortion risk measures are applied to risk densities before and after diversification, and tradeoff premiums. In addition layer dependence, mean and risk densities and diversification analysis all rely on the layer decomposition of a random quantity.


Proposed solutions in this thesis, although novel, are based on well established concepts of distortion, layer decomposition, correlation and Euler allocation. In addition proposed solutions are formulated in simple terms but yield insights to common risk and capital management problems.











\chapter{Layer dependence as a local dependence measure}

The following is a paper introducing, analyzing and illustrating layer dependence. This paper has been submitted for ASTIN Bulletin for publication.

\includepdf[pages={-}]{LD.pdf}



\chapter{Mean and risk density curves}

The following is a paper introducing, analyzing and illustrating mean and risk density curves.

\includepdf[pages={-}]{ToP.pdf}


\chapter{Insights to systemic risk and diversification}

The following is a paper analyzing systemic risk and diversification using mean and risk density curves.

\includepdf[pages={-}]{ToP.pdf}



\chapter{Tradeoff premium as a two-sided risk measure}

The following is a paper introducing, analyzing and illustrating the tradeoff premium. This paper has been submitted to Insurance: Mathematics and Economics for publication.

\includepdf[pages={-}]{ToP.pdf}


\chapter{Conclusion of this thesis}






\section{Interrelationships}


Layer dependence, mean and risk densities, diversification analysis and tradeoff premiums provide integrated solutions to risk and dependence measurement. Consistent methods and principles are applied across all proposed methods. For example distortion risk measures are applied in risk densities, diversification and tradeoff premiums. Layer dependence, mean and risk densities and diversification analysis all rely on the layer decomposition of a random quantity.




\section{Areas of future research}

The following are potential areas of future research to extend or address shortcomings of proposed methods in this thesis:
\bi

\i Time series extension.

\i Multivariate extension.

\i Two-sided risk densities.


\ei



\appendix


\addcontentsline{toc}{chapter}{Bibliography}




\bibliography{PhD}


\end{document}
